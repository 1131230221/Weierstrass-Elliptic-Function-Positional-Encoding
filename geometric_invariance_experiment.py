import torch
import torch.nn as nn
import torch.nn.functional as F
import torchvision
import torchvision.transforms as transforms
from torchvision.transforms.functional import affine, rotate
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from typing import List, Tuple, Dict, Union
import os
import json
from tqdm import tqdm
import random
from W_Ti import ImprovedViT_Ti
import matplotlib
from matplotlib import font_manager
import cv2
from PIL import Image


def _apply_publication_style():
    """åº”ç”¨å­¦æœ¯å‘è¡¨é£æ ¼çš„matplotlibè®¾ç½®"""
    matplotlib.rcParams.update({
        'font.family': 'DejaVu Sans',
        'figure.dpi': 120,
        'savefig.dpi': 300,
        'axes.titlesize': 14,
        'axes.labelsize': 12,
        'axes.linewidth': 1.2,
        'axes.edgecolor': '#222222',
        'axes.grid': True,
        'grid.color': '#AAAAAA',
        'grid.alpha': 0.25,
        'grid.linestyle': '-',
        'xtick.labelsize': 11,
        'ytick.labelsize': 11,
        'xtick.direction': 'out',
        'ytick.direction': 'out',
        'xtick.major.size': 5,
        'ytick.major.size': 5,
        'legend.frameon': True,
        'legend.fancybox': True,
        'legend.framealpha': 0.9,
        'legend.borderpad': 0.6,
    })


def _format_affine_label(params: Dict) -> str:
    """å°†ä»¿å°„å‚æ•°å­—å…¸æ ¼å¼åŒ–ä¸ºç®€æ´çš„äººç±»å¯è¯»æ ‡ç­¾ã€‚

    ä¾‹å¦‚ï¼š
        {} -> Baseline
        {"scale": 1.1, "angle": 0, "translate": [0, 0], "shear": [0, 0]} -> Scale 1.1x
        {"scale": 0.9, ...} -> Scale 0.9x
        {"translate": [5, 5]} æˆ– translate ä¸ä¸º 0 -> Translate (5,5)
        {"shear": [5, 0]} -> Shear (5,0)
        å…¶ä½™ç»„åˆå°†æ‹¼æ¥éé›¶é¡¹
    """
    if not params:
        return 'Baseline'

    pieces: List[str] = []

    scale = params.get('scale')
    if isinstance(scale, (int, float)) and abs(scale - 1.0) > 1e-6:
        pieces.append(f"Scale {scale:.2f}x")

    angle = params.get('angle')
    if isinstance(angle, (int, float)) and abs(angle) > 1e-6:
        pieces.append(f"Rotate {angle}Â°")

    translate = params.get('translate')
    if isinstance(translate, (list, tuple)) and any(abs(float(t)) > 1e-6 for t in translate):
        tx, ty = translate[0], translate[1]
        pieces.append(f"Translate ({tx},{ty})")

    shear = params.get('shear')
    if isinstance(shear, (list, tuple)) and any(abs(float(s)) > 1e-6 for s in shear):
        sx, sy = shear[0], shear[1]
        pieces.append(f"Shear ({sx},{sy})")

    if not pieces:
        return 'Baseline'
    return ' + '.join(pieces)


class GeometricTransform:
    """å‡ ä½•å˜æ¢ç±»ï¼Œæ”¯æŒæ—‹è½¬å’Œä»¿å°„å˜æ¢"""
    
    def __init__(self, transform_type: str = 'rotation'):
        """
        Args:
            transform_type: å˜æ¢ç±»å‹ ('rotation' æˆ– 'affine')
        """
        self.transform_type = transform_type
    
    def apply_rotation(self, image: torch.Tensor, angle: float) -> torch.Tensor:
        """
        åº”ç”¨æ—‹è½¬å˜æ¢
        Args:
            image: è¾“å…¥å›¾åƒtensor [C, H, W]
            angle: æ—‹è½¬è§’åº¦ï¼ˆåº¦ï¼‰
        Returns:
            æ—‹è½¬åçš„å›¾åƒtensor
        """
        if isinstance(image, torch.Tensor):
            # è½¬æ¢ä¸ºPILå›¾åƒè¿›è¡Œæ—‹è½¬
            image_pil = transforms.ToPILImage()(image)
        else:
            image_pil = image
        
        # åº”ç”¨æ—‹è½¬ï¼Œä½¿ç”¨ç™½è‰²å¡«å……
        rotated = rotate(image_pil, angle, fill=0)
        
        # è½¬æ¢å›tensor
        if isinstance(image, torch.Tensor):
            return transforms.ToTensor()(rotated)
        else:
            return rotated
    
    def apply_affine(self, image: torch.Tensor, params: Dict) -> torch.Tensor:
        """
        åº”ç”¨ä»¿å°„å˜æ¢
        Args:
            image: è¾“å…¥å›¾åƒtensor [C, H, W]
            params: ä»¿å°„å˜æ¢å‚æ•°å­—å…¸
                   åŒ…å«: translate, scale, shear, angle
        Returns:
            å˜æ¢åçš„å›¾åƒtensor
        """
        if isinstance(image, torch.Tensor):
            image_pil = transforms.ToPILImage()(image)
        else:
            image_pil = image
        
        # åº”ç”¨ä»¿å°„å˜æ¢
        transformed = affine(
            image_pil,
            angle=params.get('angle', 0),
            translate=params.get('translate', [0, 0]),
            scale=params.get('scale', 1.0),
            shear=params.get('shear', [0, 0]),
            fill=0
        )
        
        if isinstance(image, torch.Tensor):
            return transforms.ToTensor()(transformed)
        else:
            return transformed
    
    def __call__(self, image: torch.Tensor, **kwargs) -> torch.Tensor:
        """åº”ç”¨å˜æ¢"""
        if self.transform_type == 'rotation':
            angle = kwargs.get('angle', 0)
            return self.apply_rotation(image, angle)
        elif self.transform_type == 'affine':
            params = kwargs.get('params', {})
            return self.apply_affine(image, params)
        else:
            raise ValueError(f"ä¸æ”¯æŒçš„å˜æ¢ç±»å‹: {self.transform_type}")


def evaluate_model_with_transforms(model, dataloader, device, transform_configs, transform_type='rotation'):
    """
    è¯„ä¼°æ¨¡å‹åœ¨å‡ ä½•å˜æ¢ä¸‹çš„æ€§èƒ½
    
    Args:
        model: å¾…è¯„ä¼°çš„æ¨¡å‹
        dataloader: æ•°æ®åŠ è½½å™¨
        device: è®¡ç®—è®¾å¤‡
        transform_configs: å˜æ¢é…ç½®åˆ—è¡¨
        transform_type: å˜æ¢ç±»å‹ ('rotation' æˆ– 'affine')
    
    Returns:
        results: åŒ…å«ä¸åŒå˜æ¢ä¸‹å‡†ç¡®ç‡çš„å­—å…¸
    """
    model.eval()
    results = {}
    
    # åˆ›å»ºå‡ ä½•å˜æ¢å¯¹è±¡
    geometric_transform = GeometricTransform(transform_type)
    
    with torch.no_grad():
        for config in tqdm(transform_configs, desc=f"Evaluating {transform_type}"):
            correct = 0
            total = 0
            
            # æ ¹æ®å˜æ¢ç±»å‹è®¾ç½®æè¿°
            if transform_type == 'rotation':
                angle = config
                desc = f"Rotation angle {angle}Â°"
                config_key = f"rotation_{angle}"
            else:
                desc = f"Affine transform {config}"
                config_key = f"affine_{hash(str(config))}"
            
            for batch_idx, (images, labels) in enumerate(tqdm(dataloader, leave=False, desc=desc)):
                # å¯¹æ¯ä¸ªbatchåº”ç”¨å‡ ä½•å˜æ¢
                if (transform_type == 'rotation' and config != 0) or \
                   (transform_type == 'affine' and config != {}):
                    
                    transformed_images = []
                    for img in images:
                        # å…ˆåå½’ä¸€åŒ–
                        mean = torch.tensor([0.5071, 0.4865, 0.4409]).view(3, 1, 1)
                        std = torch.tensor([0.2673, 0.2564, 0.2762]).view(3, 1, 1)
                        unnorm_img = img * std + mean
                        unnorm_img = torch.clamp(unnorm_img, 0, 1)
                        
                        # åº”ç”¨å˜æ¢
                        if transform_type == 'rotation':
                            transformed_img = geometric_transform(unnorm_img, angle=config)
                        else:
                            transformed_img = geometric_transform(unnorm_img, params=config)
                        
                        # é‡æ–°å½’ä¸€åŒ–
                        transformed_img = (transformed_img - mean) / std
                        transformed_images.append(transformed_img)
                    
                    images = torch.stack(transformed_images)
                
                images, labels = images.to(device), labels.to(device)
                
                outputs = model(images)
                _, predicted = outputs.max(1)
                
                total += labels.size(0)
                correct += predicted.eq(labels).sum().item()
                
                # é™åˆ¶è¯„ä¼°çš„batchæ•°é‡ä»¥èŠ‚çœæ—¶é—´
                if batch_idx >= 50:
                    break
            
            accuracy = 100.0 * correct / total
            results[config_key] = {
                'accuracy': accuracy,
                'config': config,
                'description': desc
            }
            print(f"{desc}: accuracy = {accuracy:.2f}%")
    
    return results


def plot_geometric_invariance_comparison(wef_results, ape_results, transform_type='rotation', 
                                       save_path='geometric_invariance.png'):
    """
    ç»˜åˆ¶å‡ ä½•ä¸å˜æ€§å¯¹æ¯”å›¾
    """
    _apply_publication_style()
    
    if transform_type == 'rotation':
        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4.8))
        
        # æå–æ—‹è½¬è§’åº¦å’Œå‡†ç¡®ç‡
        angles = []
        wef_accuracies = []
        ape_accuracies = []
        
        for key in sorted(wef_results.keys()):
            if 'rotation' in key:
                angle = wef_results[key]['config']
                angles.append(angle)
                wef_accuracies.append(wef_results[key]['accuracy'])
                ape_accuracies.append(ape_results[key]['accuracy'])
        
        # ç»˜åˆ¶å‡†ç¡®ç‡å¯¹æ¯”
        ax1.plot(angles, wef_accuracies, marker='o', linestyle='-', linewidth=2.2, markersize=6,
                 color='#2E86AB', label='WEF-PE (Ours)')
        ax1.plot(angles, ape_accuracies, marker='s', linestyle='--', linewidth=2.0, markersize=6,
                 color='#A23B72', label='APE (Baseline)')
        
        ax1.set_xlabel('Rotation Angle (degrees)', fontsize=12, fontweight='bold')
        ax1.set_ylabel('Accuracy (%)', fontsize=12, fontweight='bold')
        ax1.set_title('Accuracy vs Rotation Angle', fontsize=14, fontweight='bold')
        ax1.legend(loc='best', fontsize=10)
        ax1.grid(True, alpha=0.25)
        ax1.set_xticks(angles)
        
        # æ·»åŠ æ•°å€¼æ ‡æ³¨
        for i, (angle, wef_acc, ape_acc) in enumerate(zip(angles, wef_accuracies, ape_accuracies)):
            ax1.annotate(f'{wef_acc:.1f}', (angle, wef_acc),
                        textcoords="offset points", xytext=(0,8), ha='center', 
                        fontsize=9, color='#2E86AB')
            ax1.annotate(f'{ape_acc:.1f}', (angle, ape_acc),
                        textcoords="offset points", xytext=(0,-12), ha='center', 
                        fontsize=9, color='#A23B72')
        
        # ç»˜åˆ¶æ€§èƒ½ä¸‹é™å¯¹æ¯”
        wef_baseline = wef_accuracies[0]
        ape_baseline = ape_accuracies[0]
        
        wef_degradation = [(wef_baseline - acc) for acc in wef_accuracies]
        ape_degradation = [(ape_baseline - acc) for acc in ape_accuracies]
        
        ax2.plot(angles, wef_degradation, marker='o', linestyle='-', linewidth=2.2, markersize=6,
                 color='#2E86AB', label='WEF-PE (Ours)')
        ax2.plot(angles, ape_degradation, marker='s', linestyle='--', linewidth=2.0, markersize=6,
                 color='#A23B72', label='APE (Baseline)')
        
        ax2.set_xlabel('Rotation Angle (degrees)', fontsize=12, fontweight='bold')
        ax2.set_ylabel('Degradation (pp)', fontsize=12, fontweight='bold')
        ax2.set_title('Performance Degradation', fontsize=14, fontweight='bold')
        ax2.legend(loc='best', fontsize=10)
        ax2.grid(True, alpha=0.25)
        ax2.set_xticks(angles)
        
        # æ·»åŠ æ”¹å–„å¹…åº¦æ ‡æ³¨
        for i, (angle, wef_deg, ape_deg) in enumerate(zip(angles[1:], wef_degradation[1:], ape_degradation[1:])):
            if ape_deg > wef_deg:
                improvement = ape_deg - wef_deg
                ax2.annotate(f'+{improvement:.1f} pp', 
                            (angle, (wef_deg + ape_deg) / 2), 
                            textcoords="offset points", xytext=(10,0), ha='left', 
                            fontsize=9, color='green', fontweight='bold')
        
        # é¢æ¿æ ‡ç­¾
        ax1.text(-0.1, 1.05, 'A', transform=ax1.transAxes, fontsize=14, fontweight='bold', va='top')
        ax2.text(-0.1, 1.05, 'B', transform=ax2.transAxes, fontsize=14, fontweight='bold', va='top')
    
    else:
        # ä»¿å°„å˜æ¢çš„å¯è§†åŒ–ï¼ˆç®€åŒ–ç‰ˆï¼‰
        fig, ax = plt.subplots(1, 1, figsize=(10, 6))
        
        # æå–ä»¿å°„å˜æ¢ç»“æœ
        transform_names = []
        wef_accuracies = []
        ape_accuracies = []
        
        for key in sorted(wef_results.keys()):
            if 'affine' in key:
                # ä½¿ç”¨æ›´ç®€æ´çš„æ ‡ç­¾æ›¿ä»£åŸå§‹å­—å…¸å­—ç¬¦ä¸²ï¼Œé¿å…æ ‡ç­¾è¿‡é•¿ä¸éš¾ä»¥é˜…è¯»
                params = wef_results[key]['config']
                transform_names.append(_format_affine_label(params))
                wef_accuracies.append(wef_results[key]['accuracy'])
                ape_accuracies.append(ape_results[key]['accuracy'])
        
        x = np.arange(len(transform_names))
        width = 0.35
        
        ax.bar(x - width/2, wef_accuracies, width, label='WEF-PE (Ours)', color='#2E86AB', alpha=0.8)
        ax.bar(x + width/2, ape_accuracies, width, label='APE (Baseline)', color='#A23B72', alpha=0.8)
        
        ax.set_xlabel('Affine Transformation', fontsize=12, fontweight='bold')
        ax.set_ylabel('Accuracy (%)', fontsize=12, fontweight='bold')
        ax.set_title('Accuracy under Affine Transformations', fontsize=14, fontweight='bold')
        ax.set_xticks(x)
        # æ›´å‹å¥½çš„æ ‡ç­¾æ’ç‰ˆï¼šæ—‹è½¬è§’åº¦ã€å³å¯¹é½å¹¶å¢åŠ åº•éƒ¨ç•™ç™½
        ax.set_xticklabels(transform_names, rotation=30, ha='right')
        ax.margins(x=0.02)
        ax.set_ylim(bottom=max(0, min(wef_accuracies + ape_accuracies) - 5))
        ax.legend()
        ax.grid(True, alpha=0.25)
    
    plt.tight_layout()
    
    # ä¿å­˜å›¾ç‰‡
    base, ext = os.path.splitext(save_path)
    plt.savefig(f'{base}.png', dpi=300, bbox_inches='tight')
    try:
        plt.savefig(f'{base}.pdf', bbox_inches='tight')
    except Exception:
        pass
    
    print(f"Figure saved to: {save_path}")
    plt.show()


def create_test_dataloader_cifar100_geometric(batch_size=64, num_workers=4):
    """åˆ›å»ºç”¨äºå‡ ä½•å˜æ¢æµ‹è¯•çš„CIFAR-100æ•°æ®åŠ è½½å™¨"""
    test_transform = transforms.Compose([
        transforms.Resize((224, 224)),
        transforms.ToTensor(),
        transforms.Normalize(mean=[0.5071, 0.4865, 0.4409],
                           std=[0.2673, 0.2564, 0.2762])
    ])
    
    test_dataset = torchvision.datasets.CIFAR100(
        root='/root/shared-nvme', train=False, download=False, transform=test_transform
    )
    
    test_loader = torch.utils.data.DataLoader(
        test_dataset, batch_size=batch_size, shuffle=False,
        num_workers=num_workers, pin_memory=True
    )
    
    return test_loader


def load_trained_models_for_geometric_test(wef_model_path='best_wef_vit_ti.pth', 
                                          ape_model_path='best_ape_vit_ti.pth', 
                                          device='cuda'):
    """åŠ è½½è®­ç»ƒå¥½çš„æ¨¡å‹ç”¨äºå‡ ä½•ä¸å˜æ€§æµ‹è¯•"""
    
    # åˆ›å»ºWEFæ¨¡å‹å¹¶åŠ è½½æƒé‡
    wef_model = ImprovedViT_Ti(
        img_size=224,
        patch_size=16,
        in_channels=3,
        num_classes=100,
        embed_dim=192,
        depth=12,
        num_heads=3,
        mlp_ratio=4.0,
        dropout=0.05,
        drop_path=0.05,
        use_wef=True
    )
    
    if os.path.exists(wef_model_path):
        print(f"åŠ è½½WEFæ¨¡å‹æƒé‡: {wef_model_path}")
        wef_model.load_state_dict(torch.load(wef_model_path, map_location=device))
    else:
        print(f"è­¦å‘Š: æœªæ‰¾åˆ°WEFæ¨¡å‹æƒé‡æ–‡ä»¶ {wef_model_path}")
    
    wef_model = wef_model.to(device)
    
    # åˆ›å»ºAPEæ¨¡å‹å¹¶åŠ è½½æƒé‡
    ape_model = ImprovedViT_Ti(
        img_size=224,
        patch_size=16,
        in_channels=3,
        num_classes=100,
        embed_dim=192,
        depth=12,
        num_heads=3,
        mlp_ratio=4.0,
        dropout=0.05,
        drop_path=0.05,
        use_wef=False
    )
    
    if os.path.exists(ape_model_path):
        print(f"åŠ è½½APEæ¨¡å‹æƒé‡: {ape_model_path}")
        ape_model.load_state_dict(torch.load(ape_model_path, map_location=device))
    else:
        print(f"è­¦å‘Š: æœªæ‰¾åˆ°APEæ¨¡å‹æƒé‡æ–‡ä»¶ {ape_model_path}")
        print("å°†ä½¿ç”¨å¿«é€Ÿè®­ç»ƒçš„APEåŸºçº¿æ¨¡å‹")
        from occlusion_experiment import train_ape_baseline_quickly
        ape_model = train_ape_baseline_quickly(ape_model, device)
    
    ape_model = ape_model.to(device)
    
    return wef_model, ape_model


def run_rotation_invariance_experiment():
    """è¿è¡Œæ—‹è½¬ä¸å˜æ€§å®éªŒ"""
    print("=" * 60)
    print("WEF-PE vs APE æ—‹è½¬ä¸å˜æ€§å¯¹æ¯”å®éªŒ")
    print("=" * 60)
    
    # è®¾ç½®éšæœºç§å­
    torch.manual_seed(42)
    np.random.seed(42)
    random.seed(42)
    
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    print(f"ä½¿ç”¨è®¾å¤‡: {device}")
    
    # åˆ›å»ºæµ‹è¯•æ•°æ®åŠ è½½å™¨
    print("åˆ›å»ºæµ‹è¯•æ•°æ®åŠ è½½å™¨...")
    test_loader = create_test_dataloader_cifar100_geometric(batch_size=32, num_workers=4)
    
    # åŠ è½½è®­ç»ƒå¥½çš„æ¨¡å‹
    print("åŠ è½½è®­ç»ƒå¥½çš„æ¨¡å‹...")
    wef_model, ape_model = load_trained_models_for_geometric_test(device=device)
    
    # å®šä¹‰æ—‹è½¬è§’åº¦
    rotation_angles = [0, 5, 10, 15, 30]  # åº¦
    print(f"æµ‹è¯•æ—‹è½¬è§’åº¦: {rotation_angles}Â°")
    
    # è¯„ä¼°WEFæ¨¡å‹
    print("\nè¯„ä¼°WEF-PEæ¨¡å‹æ—‹è½¬ä¸å˜æ€§...")
    wef_results = evaluate_model_with_transforms(
        wef_model, test_loader, device, rotation_angles, 'rotation'
    )
    
    # è¯„ä¼°APEåŸºçº¿æ¨¡å‹
    print("\nè¯„ä¼°APEåŸºçº¿æ¨¡å‹æ—‹è½¬ä¸å˜æ€§...")
    ape_results = evaluate_model_with_transforms(
        ape_model, test_loader, device, rotation_angles, 'rotation'
    )
    
    return wef_results, ape_results


def run_affine_invariance_experiment():
    """è¿è¡Œä»¿å°„å˜æ¢ä¸å˜æ€§å®éªŒ"""
    print("=" * 60)
    print("WEF-PE vs APE ä»¿å°„å˜æ¢ä¸å˜æ€§å¯¹æ¯”å®éªŒ")
    print("=" * 60)
    
    # è®¾ç½®éšæœºç§å­
    torch.manual_seed(42)
    np.random.seed(42)
    random.seed(42)
    
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    print(f"ä½¿ç”¨è®¾å¤‡: {device}")
    
    # åˆ›å»ºæµ‹è¯•æ•°æ®åŠ è½½å™¨
    print("åˆ›å»ºæµ‹è¯•æ•°æ®åŠ è½½å™¨...")
    test_loader = create_test_dataloader_cifar100_geometric(batch_size=32, num_workers=4)
    
    # åŠ è½½è®­ç»ƒå¥½çš„æ¨¡å‹
    print("åŠ è½½è®­ç»ƒå¥½çš„æ¨¡å‹...")
    wef_model, ape_model = load_trained_models_for_geometric_test(device=device)
    
    # å®šä¹‰ä»¿å°„å˜æ¢å‚æ•°
    affine_transforms = [
        {},  # æ— å˜æ¢ï¼ˆåŸºçº¿ï¼‰
        {'scale': 1.1, 'angle': 0, 'translate': [0, 0], 'shear': [0, 0]},  # è½»å¾®ç¼©æ”¾
        {'scale': 0.9, 'angle': 0, 'translate': [0, 0], 'shear': [0, 0]},  # è½»å¾®ç¼©å°
        {'scale': 1.0, 'angle': 0, 'translate': [5, 5], 'shear': [0, 0]},  # å¹³ç§»
        {'scale': 1.0, 'angle': 0, 'translate': [0, 0], 'shear': [5, 0]},  # è½»å¾®å‰ªåˆ‡
    ]
    
    print(f"æµ‹è¯•ä»¿å°„å˜æ¢é…ç½®æ•°é‡: {len(affine_transforms)}")
    
    # è¯„ä¼°WEFæ¨¡å‹
    print("\nè¯„ä¼°WEF-PEæ¨¡å‹ä»¿å°„ä¸å˜æ€§...")
    wef_results = evaluate_model_with_transforms(
        wef_model, test_loader, device, affine_transforms, 'affine'
    )
    
    # è¯„ä¼°APEåŸºçº¿æ¨¡å‹
    print("\nè¯„ä¼°APEåŸºçº¿æ¨¡å‹ä»¿å°„ä¸å˜æ€§...")
    ape_results = evaluate_model_with_transforms(
        ape_model, test_loader, device, affine_transforms, 'affine'
    )
    
    return wef_results, ape_results


def print_detailed_results(wef_results, ape_results, experiment_type='rotation'):
    """æ‰“å°è¯¦ç»†çš„å®éªŒç»“æœ"""
    print("\n" + "=" * 60)
    print("å®éªŒç»“æœè¯¦ç»†åˆ†æ")
    print("=" * 60)
    
    if experiment_type == 'rotation':
        print(f"{'æ—‹è½¬è§’åº¦':<12} {'WEF-PE':<12} {'APE':<12} {'æ”¹å–„':<12}")
        print("-" * 50)
        
        angles = []
        improvements = []
        
        for key in sorted(wef_results.keys()):
            if 'rotation' in key:
                angle = wef_results[key]['config']
                wef_acc = wef_results[key]['accuracy']
                ape_acc = ape_results[key]['accuracy']
                improvement = wef_acc - ape_acc
                
                angles.append(f"{angle}Â°")
                improvements.append(improvement)
                
                print(f"{angle:>8}Â°   {wef_acc:>8.2f}%   {ape_acc:>8.2f}%   {improvement:>+8.2f}pp")
    
    else:  # affine
        print(f"{'å˜æ¢ç±»å‹':<20} {'WEF-PE':<12} {'APE':<12} {'æ”¹å–„':<12}")
        print("-" * 58)
        
        improvements = []
        
        for key in sorted(wef_results.keys()):
            if 'affine' in key:
                desc = wef_results[key]['description']
                wef_acc = wef_results[key]['accuracy']
                ape_acc = ape_results[key]['accuracy']
                improvement = wef_acc - ape_acc
                
                improvements.append(improvement)
                
                print(f"{desc:<18} {wef_acc:>8.2f}%   {ape_acc:>8.2f}%   {improvement:>+8.2f}pp")
    
    # è®¡ç®—å¹³å‡æ”¹å–„
    if len(improvements) > 1:  # æ’é™¤åŸºçº¿æƒ…å†µ
        avg_improvement = np.mean(improvements[1:])
        print(f"\nå¹³å‡æ”¹å–„: {avg_improvement:+.2f} ä¸ªç™¾åˆ†ç‚¹")
    
    return improvements


def run_complete_geometric_invariance_experiment():
    """è¿è¡Œå®Œæ•´çš„å‡ ä½•ä¸å˜æ€§å®éªŒ"""
    print("ğŸ”„ å¼€å§‹å‡ ä½•ä¸å˜æ€§ç»¼åˆå®éªŒ...")
    
    # 1. æ—‹è½¬ä¸å˜æ€§å®éªŒ
    print("\nğŸ“ ç¬¬ä¸€é˜¶æ®µï¼šæ—‹è½¬ä¸å˜æ€§æµ‹è¯•")
    wef_rotation_results, ape_rotation_results = run_rotation_invariance_experiment()
    
    # æ‰“å°æ—‹è½¬å®éªŒè¯¦ç»†ç»“æœ
    rotation_improvements = print_detailed_results(
        wef_rotation_results, ape_rotation_results, 'rotation'
    )
    
    # ç»˜åˆ¶æ—‹è½¬ä¸å˜æ€§å¯¹æ¯”å›¾
    print("\nç»˜åˆ¶æ—‹è½¬ä¸å˜æ€§å¯¹æ¯”å›¾...")
    plot_geometric_invariance_comparison(
        wef_rotation_results, ape_rotation_results, 
        'rotation', 'rotation_invariance.png'
    )
    
    # 2. ä»¿å°„å˜æ¢ä¸å˜æ€§å®éªŒ
    print("\nğŸ”§ ç¬¬äºŒé˜¶æ®µï¼šä»¿å°„å˜æ¢ä¸å˜æ€§æµ‹è¯•")
    wef_affine_results, ape_affine_results = run_affine_invariance_experiment()
    
    # æ‰“å°ä»¿å°„å˜æ¢å®éªŒè¯¦ç»†ç»“æœ
    affine_improvements = print_detailed_results(
        wef_affine_results, ape_affine_results, 'affine'
    )
    
    # ç»˜åˆ¶ä»¿å°„å˜æ¢ä¸å˜æ€§å¯¹æ¯”å›¾
    print("\nç»˜åˆ¶ä»¿å°„å˜æ¢ä¸å˜æ€§å¯¹æ¯”å›¾...")
    plot_geometric_invariance_comparison(
        wef_affine_results, ape_affine_results, 
        'affine', 'affine_invariance.png'
    )
    
    # ä¿å­˜å®Œæ•´ç»“æœ
    complete_results = {
        'rotation_results': {
            'wef': wef_rotation_results,
            'ape': ape_rotation_results,
            'average_improvement': float(np.mean(rotation_improvements[1:]))
        },
        'affine_results': {
            'wef': wef_affine_results,
            'ape': ape_affine_results,
            'average_improvement': float(np.mean(affine_improvements[1:]))
        }
    }
    
    with open('geometric_invariance_results.json', 'w', encoding='utf-8') as f:
        json.dump(complete_results, f, indent=2, ensure_ascii=False)
    
    print("\n" + "=" * 60)
    print("ğŸ¯ å‡ ä½•ä¸å˜æ€§å®éªŒæ€»ç»“")
    print("=" * 60)
    print(f"æ—‹è½¬ä¸å˜æ€§å¹³å‡æ”¹å–„: {np.mean(rotation_improvements[1:]):+.2f} ä¸ªç™¾åˆ†ç‚¹")
    print(f"ä»¿å°„å˜æ¢ä¸å˜æ€§å¹³å‡æ”¹å–„: {np.mean(affine_improvements[1:]):+.2f} ä¸ªç™¾åˆ†ç‚¹")
    print("\nå®éªŒç»“æœå·²ä¿å­˜åˆ°: geometric_invariance_results.json")
    print("å‡ ä½•ä¸å˜æ€§å®éªŒå®Œæˆ! âœ…")
    
    return complete_results


if __name__ == "__main__":
    # è¿è¡Œå®Œæ•´çš„å‡ ä½•ä¸å˜æ€§å®éªŒ
    results = run_complete_geometric_invariance_experiment()