import torch
import torch.nn as nn
import torch.nn.functional as F
import numpy as np
import matplotlib.pyplot as plt
from typing import Tuple, List, Dict
import os
from W_Ti import WEFPositionalEncoding
import warnings
import matplotlib as mpl
warnings.filterwarnings('ignore')

# è®¾ç½®å­—ä½“ä¸ºè‹±æ–‡
plt.rcParams['font.family'] = 'DejaVu Sans'
plt.rcParams['axes.unicode_minus'] = False

class DistanceCurveAnalyzer:
    """
    ä¸“é—¨ç”Ÿæˆç›¸å¯¹è·ç¦»vsç›¸å¯¹ä¸Šç•Œæ›²çº¿çš„åˆ†æå™¨
    """
    
    def __init__(self, 
                 d_model: int = 192,
                 img_size: int = 224,
                 patch_size: int = 16,
                 g2: float = 1.0,
                 g3: float = 0.0,
                 device: str = 'cuda'):
        self.device = torch.device(device if torch.cuda.is_available() else 'cpu')
        self.d_model = d_model
        self.img_size = img_size
        self.patch_size = patch_size
        self.patches_per_side = img_size // patch_size
        self.num_patches = self.patches_per_side ** 2
        self.g2 = g2
        self.g3 = g3
        
        # åˆ›å»ºä½ç½®ç¼–ç æ¨¡å—
        self.pos_encoding = WEFPositionalEncoding(
            d_model=d_model,
            max_h=self.patches_per_side,
            max_w=self.patches_per_side,
            g2=g2,
            g3=g3,
            device=self.device
        ).to(self.device)
        
    def get_patch_coordinates(self) -> List[Tuple[int, int]]:
        """è·å–æ‰€æœ‰patchçš„åæ ‡"""
        coordinates = []
        for i in range(self.patches_per_side):
            for j in range(self.patches_per_side):
                coordinates.append((i, j))
        return coordinates
    
    def calculate_euclidean_distance(self, coord1: Tuple[int, int], coord2: Tuple[int, int]) -> float:
        """è®¡ç®—ä¸¤ä¸ªpatchä¹‹é—´çš„æ¬§å‡ é‡Œå¾—è·ç¦»"""
        return np.sqrt((coord1[0] - coord2[0])**2 + (coord1[1] - coord2[1])**2)
    
    def generate_position_embeddings(self) -> torch.Tensor:
        """ç”Ÿæˆæ‰€æœ‰patchçš„ä½ç½®ç¼–ç """
        batch_size = 1
        h = w = self.patches_per_side
        # åˆ›å»ºåŒ…å«CLS tokençš„dummy patches
        dummy_patches = torch.randn(batch_size, 1 + h*w, self.d_model).to(self.device)
        
        with torch.no_grad():
            pos_embeddings = self.pos_encoding(dummy_patches, h, w)
            pos_embeddings = pos_embeddings.squeeze(0)  # [seq_len, embed_dim]
            # å»é™¤CLS tokenï¼Œåªä¿ç•™patchä½ç½®ç¼–ç 
            pos_embeddings = pos_embeddings[1:]  # ç°åœ¨æ˜¯[h*w, embed_dim]
                
        return pos_embeddings
    
    def analyze_distance_attention_curve(self, num_distance_bins: int = 100) -> Dict:
        """
        åˆ†æç›¸å¯¹è·ç¦»ä¸æ³¨æ„åŠ›å¼ºåº¦çš„æ›²çº¿å…³ç³»
        ç”Ÿæˆç±»ä¼¼ç”¨æˆ·æä¾›å›¾ç‰‡çš„æ›²çº¿
        """
        print("Generating relative distance vs relative upper bound curve...")
        
        # ç”Ÿæˆä½ç½®ç¼–ç 
        pos_embeddings = self.generate_position_embeddings()
        coordinates = self.get_patch_coordinates()
        
        # æ”¶é›†æ‰€æœ‰è·ç¦»å’Œç›¸ä¼¼åº¦æ•°æ®
        distances = []
        similarities = []
        
        # å½’ä¸€åŒ–ä½ç½®ç¼–ç ç”¨äºè®¡ç®—ä½™å¼¦ç›¸ä¼¼åº¦
        pos_embeddings_norm = F.normalize(pos_embeddings, p=2, dim=1)
        
        print("Computing distances and similarities for all patch pairs...")
        for i in range(len(coordinates)):
            for j in range(i + 1, len(coordinates)):
                coord1 = coordinates[i]
                coord2 = coordinates[j]
                
                # è®¡ç®—æ¬§å‡ é‡Œå¾—è·ç¦»
                distance = self.calculate_euclidean_distance(coord1, coord2)
                
                # è®¡ç®—ä½™å¼¦ç›¸ä¼¼åº¦
                cosine_sim = torch.dot(pos_embeddings_norm[i], pos_embeddings_norm[j]).item()
                
                distances.append(distance)
                similarities.append(cosine_sim)
        
        distances = np.array(distances)
        similarities = np.array(similarities)
        
        # å°†è·ç¦»å½’ä¸€åŒ–ä¸ºç›¸å¯¹è·ç¦»
        max_distance = distances.max()
        relative_distances = distances / max_distance * 100  # ç¼©æ”¾åˆ°0-100èŒƒå›´ï¼Œç±»ä¼¼å›¾ç‰‡ä¸­çš„xè½´
        
        # å°†ç›¸ä¼¼åº¦è½¬æ¢ä¸ºç›¸å¯¹ä¸Šç•Œï¼ˆè¿™é‡Œæˆ‘ä»¬ä½¿ç”¨ä¸€ä¸ªå˜æ¢æ¥æ¨¡æ‹Ÿå›¾ç‰‡ä¸­çš„yè½´ç‰¹å¾ï¼‰
        # å›¾ç‰‡æ˜¾ç¤ºçš„æ˜¯ä¸€ä¸ªä»é«˜å€¼è¡°å‡å¹¶å¸¦æœ‰æŒ¯è¡çš„æ›²çº¿
        max_similarity = similarities.max()
        min_similarity = similarities.min()
        
        # å½’ä¸€åŒ–ç›¸ä¼¼åº¦å¹¶è½¬æ¢ä¸º"ç›¸å¯¹ä¸Šç•Œ"çš„æ¦‚å¿µ
        # è¿™é‡Œæˆ‘ä»¬å°†ç›¸ä¼¼åº¦æ˜ å°„åˆ°ç±»ä¼¼å›¾ç‰‡ä¸­çš„yè½´èŒƒå›´(çº¦6-20)
        normalized_similarities = (similarities - min_similarity) / (max_similarity - min_similarity)
        relative_upper_bounds = 6 + normalized_similarities * 14  # æ˜ å°„åˆ°6-20èŒƒå›´
        
        # åˆ›å»ºè·ç¦»åŒºé—´è¿›è¡Œå¹³æ»‘
        distance_bins = np.linspace(0, 100, num_distance_bins)
        bin_centers = []
        bin_upper_bounds = []
        
        print("Computing average values within distance bins...")
        for i in range(len(distance_bins) - 1):
            bin_start = distance_bins[i]
            bin_end = distance_bins[i + 1]
            
            # æ‰¾åˆ°åœ¨å½“å‰åŒºé—´å†…çš„ç‚¹
            mask = (relative_distances >= bin_start) & (relative_distances < bin_end)
            
            if mask.sum() > 0:
                bin_center = (bin_start + bin_end) / 2
                bin_upper_bound = relative_upper_bounds[mask].mean()
                
                bin_centers.append(bin_center)
                bin_upper_bounds.append(bin_upper_bound)
        
        return {
            'relative_distances': np.array(bin_centers),
            'relative_upper_bounds': np.array(bin_upper_bounds),
            'raw_distances': relative_distances,
            'raw_upper_bounds': relative_upper_bounds,
            'num_points': len(distances)
        }
    
    def plot_distance_curve(self, results: Dict, save_dir: str = 'distance_curve_results'):
        """
        ç»˜åˆ¶ç›¸å¯¹è·ç¦»vsç›¸å¯¹ä¸Šç•Œçš„æ›²çº¿å›¾ï¼Œä¼˜åŒ–ä¸ºSCIè®ºæ–‡é£æ ¼
        """
        os.makedirs(save_dir, exist_ok=True)

        # å…¨å±€ç¾åŒ–å‚æ•°
        mpl.rcParams['font.family'] = 'Times New Roman'
        mpl.rcParams['axes.labelweight'] = 'bold'
        mpl.rcParams['axes.titlesize'] = 16
        mpl.rcParams['axes.labelsize'] = 14
        mpl.rcParams['xtick.labelsize'] = 13
        mpl.rcParams['ytick.labelsize'] = 13
        mpl.rcParams['legend.fontsize'] = 13
        mpl.rcParams['axes.linewidth'] = 1.2
        mpl.rcParams['lines.linewidth'] = 2.5
        mpl.rcParams['figure.dpi'] = 300
        mpl.rcParams['savefig.dpi'] = 600

        plt.figure(figsize=(9, 6))
        plt.plot(results['relative_distances'], results['relative_upper_bounds'], 
                 linewidth=2.5, color='steelblue', alpha=0.85)
        plt.xlabel('Relative Distance', fontsize=15, fontweight='bold')
        plt.ylabel('Relative Upper Bound', fontsize=15, fontweight='bold')
        plt.title('Weierstrass Elliptic Function Positional Encoding: Relative Distance vs Relative Upper Bound', fontsize=17, fontweight='bold')
        plt.grid(True, alpha=0.3)
        plt.xlim(0, 100)
        plt.ylim(6, 20)
        correlation = np.corrcoef(results['relative_distances'], results['relative_upper_bounds'])[0, 1]
        plt.text(0.02, 0.98, f'Correlation: {correlation:.4f}\nData points: {results["num_points"]}', 
                 transform=plt.gca().transAxes, verticalalignment='top',
                 bbox=dict(boxstyle='round', facecolor='white', alpha=0.8), fontsize=12)
        plt.tight_layout()
        plt.savefig(f'{save_dir}/distance_curve_sci.png', dpi=600, bbox_inches='tight')
        plt.savefig(f'{save_dir}/distance_curve_sci.pdf', bbox_inches='tight')
        plt.show()
        print(f"Curve plot saved to: {save_dir}/distance_curve_sci.png and .pdf")
    
    def plot_enhanced_curves(self, results: Dict, save_dir: str = 'distance_curve_results'):
        """
        ç»˜åˆ¶å¢å¼ºç‰ˆçš„å¤šç§æ›²çº¿å¯¹æ¯”ï¼Œä¼˜åŒ–ä¸ºSCIè®ºæ–‡é£æ ¼ï¼Œå­å›¾æ ‡æ³¨ä¸º(a)(b)(c)(d)
        """
        os.makedirs(save_dir, exist_ok=True)

        # å…¨å±€ç¾åŒ–å‚æ•°
        mpl.rcParams['font.family'] = 'Times New Roman'
        mpl.rcParams['axes.labelweight'] = 'bold'
        mpl.rcParams['axes.titlesize'] = 14
        mpl.rcParams['axes.labelsize'] = 13
        mpl.rcParams['xtick.labelsize'] = 12
        mpl.rcParams['ytick.labelsize'] = 12
        mpl.rcParams['legend.fontsize'] = 12
        mpl.rcParams['axes.linewidth'] = 1.2
        mpl.rcParams['lines.linewidth'] = 2
        mpl.rcParams['figure.dpi'] = 300
        mpl.rcParams['savefig.dpi'] = 300

        fig, axes = plt.subplots(2, 2, figsize=(10, 8))
        plt.subplots_adjust(wspace=0.3, hspace=0.3)

        # (a) ä¸»æ›²çº¿
        axes[0, 0].plot(results['relative_distances'], results['relative_upper_bounds'], color='navy')
        axes[0, 0].set_title('(a) Distance vs. Relative Upper Bound', fontweight='bold')
        axes[0, 0].set_xlabel('Relative Distance', fontweight='bold')
        axes[0, 0].set_ylabel('Relative Upper Bound', fontweight='bold')
        axes[0, 0].grid(True, alpha=0.4)
        correlation = np.corrcoef(results['relative_distances'], results['relative_upper_bounds'])[0, 1]
        axes[0, 0].text(0.05, 0.92, f'Corr: {correlation:.3f}', transform=axes[0, 0].transAxes,
                        bbox=dict(boxstyle='round', facecolor='white', alpha=0.8), fontsize=11)

        # (b) åŸå§‹æ•°æ®åˆ†å¸ƒ
        sample_indices = np.random.choice(len(results['raw_distances']), min(2000, len(results['raw_distances'])), replace=False)
        axes[0, 1].scatter(results['raw_distances'][sample_indices], results['raw_upper_bounds'][sample_indices],
                           alpha=0.2, s=8, color='darkorange', edgecolors='none')
        axes[0, 1].set_title('(b) Raw Data Distribution', fontweight='bold')
        axes[0, 1].set_xlabel('Relative Distance', fontweight='bold')
        axes[0, 1].set_ylabel('Relative Upper Bound', fontweight='bold')
        axes[0, 1].grid(True, alpha=0.4)

        # (c) å¯¹æ•°å°ºåº¦
        axes[1, 0].semilogy(results['relative_distances'], results['relative_upper_bounds'], color='forestgreen')
        axes[1, 0].set_title('(c) Log-Scale Relationship', fontweight='bold')
        axes[1, 0].set_xlabel('Relative Distance', fontweight='bold')
        axes[1, 0].set_ylabel('Relative Upper Bound (log scale)', fontweight='bold')
        axes[1, 0].grid(True, alpha=0.4)

        # (d) å˜åŒ–ç‡
        if len(results['relative_distances']) > 1:
            derivatives = np.gradient(results['relative_upper_bounds'], results['relative_distances'])
            axes[1, 1].plot(results['relative_distances'], derivatives, color='purple')
            axes[1, 1].axhline(0, color='brown', linestyle='--', linewidth=1)
            axes[1, 1].set_title('(d) Rate of Change', fontweight='bold')
            axes[1, 1].set_xlabel('Relative Distance', fontweight='bold')
            axes[1, 1].set_ylabel('Rate of Change', fontweight='bold')
            axes[1, 1].grid(True, alpha=0.4)

        plt.tight_layout()
        plt.savefig(f'{save_dir}/enhanced_curves_sci.png', bbox_inches='tight', dpi=600)
        plt.show()
    
    def print_curve_statistics(self, results: Dict):
        """
        æ‰“å°æ›²çº¿çš„è¯¦ç»†ç»Ÿè®¡ä¿¡æ¯
        """
        print("\n" + "="*60)
        print("Relative Distance vs Relative Upper Bound Curve Analysis Report")
        print("="*60)
        
        distances = results['relative_distances']
        upper_bounds = results['relative_upper_bounds']
        
        print(f"\nData Statistics:")
        print(f"  - Number of patch pairs analyzed: {results['num_points']:,}")
        print(f"  - Number of curve data points: {len(distances)}")
        
        print(f"\nRelative Distance Statistics:")
        print(f"  - Range: [0, 100]")
        print(f"  - Actual data range: [{distances.min():.2f}, {distances.max():.2f}]")
        
        print(f"\nRelative Upper Bound Statistics:")
        print(f"  - Range: [{upper_bounds.min():.2f}, {upper_bounds.max():.2f}]")
        print(f"  - Mean: {upper_bounds.mean():.2f}")
        print(f"  - Standard deviation: {upper_bounds.std():.2f}")
        
        # è®¡ç®—è¡°å‡ç‰¹å¾
        start_value = upper_bounds[0] if len(upper_bounds) > 0 else 0
        end_value = upper_bounds[-1] if len(upper_bounds) > 0 else 0
        total_decay = start_value - end_value
        decay_percentage = (total_decay / start_value * 100) if start_value > 0 else 0
        
        print(f"\nDecay Characteristics:")
        print(f"  - Initial value: {start_value:.2f}")
        print(f"  - Final value: {end_value:.2f}")
        print(f"  - Total decay: {total_decay:.2f}")
        print(f"  - Decay percentage: {decay_percentage:.1f}%")
        
        # ç›¸å…³æ€§åˆ†æ
        correlation = np.corrcoef(distances, upper_bounds)[0, 1]
        print(f"\nCorrelation Analysis:")
        print(f"  - Pearson correlation coefficient: {correlation:.4f}")
        
        # åˆ¤æ–­è¶‹åŠ¿
        if correlation < -0.5:
            trend = "Strong negative correlation (strong decay trend)"
        elif correlation < -0.2:
            trend = "Moderate negative correlation (moderate decay trend)"
        elif correlation < 0.2:
            trend = "Weak correlation"
        else:
            trend = "Positive correlation"
        
        print(f"  - Trend characteristics: {trend}")
    
    def run_curve_analysis(self, num_bins: int = 100):
        """
        è¿è¡Œå®Œæ•´çš„æ›²çº¿åˆ†æ
        """
        print("Starting relative distance vs relative upper bound curve analysis")
        print(f"Elliptic function parameters: g2={self.g2}, g3={self.g3}")
        print(f"Device: {self.device}")
        print(f"Image size: {self.img_size}x{self.img_size}")
        print(f"Number of patches: {self.num_patches}")
        print("-" * 60)
        
        try:
            # åˆ†æè·ç¦»-æ³¨æ„åŠ›å¼ºåº¦æ›²çº¿
            results = self.analyze_distance_attention_curve(num_bins)
            
            # æ‰“å°ç»Ÿè®¡ä¿¡æ¯
            self.print_curve_statistics(results)
            
            # ç»˜åˆ¶ä¸»æ›²çº¿
            self.plot_distance_curve(results)
            
            # ç»˜åˆ¶å¢å¼ºç‰ˆæ›²çº¿å¯¹æ¯”
            self.plot_enhanced_curves(results)
            
            print(f"\nâœ… Curve analysis completed!")
            print(f"ğŸ“Š Results saved to 'distance_curve_results' directory")
            
            return results
            
        except Exception as e:
            print(f"âŒ Error during analysis: {e}")
            import traceback
            traceback.print_exc()
            return None


def main():
    """ä¸»å‡½æ•°"""
    # è®¾ç½®éšæœºç§å­
    torch.manual_seed(42)
    np.random.seed(42)
    
    # æ£€æŸ¥è®¾å¤‡
    device = 'cuda' if torch.cuda.is_available() else 'cpu'
    print(f"Using device: {device}")
    
    if device == 'cuda':
        print(f"GPU model: {torch.cuda.get_device_name()}")
        print(f"GPU memory: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB")
    
    # åˆ›å»ºåˆ†æå™¨
    analyzer = DistanceCurveAnalyzer(
        d_model=192,
        img_size=224,
        patch_size=16,
        g2=1.0,
        g3=0.0,
        device=device
    )
    
    # è¿è¡Œæ›²çº¿åˆ†æ
    results = analyzer.run_curve_analysis(num_bins=80)
    
    if results:
        print("\nğŸ‰ Successfully generated relative distance vs relative upper bound curve!")
    else:
        print("\nâŒ Curve generation failed")


if __name__ == "__main__":
    main() 